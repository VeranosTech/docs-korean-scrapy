# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2008-2016, Scrapy developers
# This file is distributed under the same license as the Scrapy package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2017.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Scrapy 1.4\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2017-12-13 13:17+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.4.0\n"

#: ../docs/topics/selectors.rst:5
msgid "Selectors"
msgstr "셀렉터(Selector)"

#: ../docs/topics/selectors.rst:7
msgid ""
"When you're scraping web pages, the most common task you need to perform "
"is to extract data from the HTML source. There are several libraries "
"available to achieve this:"
msgstr ""
"웹 페이지를 스크랩할 때, 가장 많이 해야 하는 작업은 HTML 자료로부터 데이터를 추출하는 일이다. 이런 일을 할 수 있는 "
"라이브러리는 몇 가지가 있다:"

#: ../docs/topics/selectors.rst:11
msgid ""
"`BeautifulSoup`_ is a very popular web scraping library among Python "
"programmers which constructs a Python object based on the structure of "
"the HTML code and also deals with bad markup reasonably well, but it has "
"one drawback: it's slow."
msgstr ""
"`BeautifulSoup`_\\ 는 파이썬(Python) 프로그래머 사이에서 가장 인기있는 웹 스크랩핑 라이브러리로 HTML의 "
"구조를 기반으로 파이썬 객체를 생성하고 나쁜 마크업을 꽤 잘 처리한다. 하지만 한 가지 단점이 있는데 느리다는 것이다."

#: ../docs/topics/selectors.rst:16
msgid ""
"`lxml`_ is an XML parsing library (which also parses HTML) with a "
"pythonic API based on `ElementTree`_. (lxml is not part of the Python "
"standard library.)"
msgstr ""
"`lxml`_\\ 는 XML 파싱 라이브러리로 (HTML도 파싱할 수 있다) `ElementTree`_\\ 을 기반으로 하는 "
"파이썬스러운 API다. (lxml은 파이썬 기본 라이브러리는 아니다.)"

#: ../docs/topics/selectors.rst:20
msgid ""
"Scrapy comes with its own mechanism for extracting data. They're called "
"selectors because they \"select\" certain parts of the HTML document "
"specified either by `XPath`_ or `CSS`_ expressions."
msgstr ""
"스크래피(Scrapy)는 자체적인 추출 매커니즘을 가지고 있다. 이 매커니즘은 `XPath`_\\ 나 `CSS`_\\ 표현으로 "
"지정된 HTML 문서의 특정 부분을 선택하기 때문에 셀렉터라고 불린다."

#: ../docs/topics/selectors.rst:24
msgid ""
"`XPath`_ is a language for selecting nodes in XML documents, which can "
"also be used with HTML. `CSS`_ is a language for applying styles to HTML "
"documents. It defines selectors to associate those styles with specific "
"HTML elements."
msgstr ""
"`XPath`_\\ 는 XML 문서에 있는 노드를 선택하는 언어이며 HTML에서도 사용할 수 있다. `CSS`_\\ 는 HTML "
"문서에 스타일을 적용시키기 위한 언어로 그 스타일과 특정한 HTML 요소를 연관시키는 셀렉터를 정의한다."

#: ../docs/topics/selectors.rst:28
msgid ""
"Scrapy selectors are built over the `lxml`_ library, which means they're "
"very similar in speed and parsing accuracy."
msgstr "스크래피 셀렉터는 `lxml`_ 라이브러리를 기반으로 만들어져서 속도와 파싱의 정확도 면에서 매우 유사하다."

#: ../docs/topics/selectors.rst:31
msgid ""
"This page explains how selectors work and describes their API which is "
"very small and simple, unlike the `lxml`_ API which is much bigger "
"because the `lxml`_ library can be used for many other tasks, besides "
"selecting markup documents."
msgstr ""
"이 페이지는 셀렉터가 작동하는 방식과 매우 작고 간단한 API에 대해 설명했다. (`lxml`_ API는 마크업 문서를 선택하는 것"
" 뿐만 아니라 다른 많은 작업에서 사용되는 라이브러리이기 때문에 훨씬 크다.)"

#: ../docs/topics/selectors.rst:36
msgid ""
"For a complete reference of the selectors API see :ref:`Selector "
"reference <topics-selectors-ref>`"
msgstr ""
"셀렉터 API에 대한 완전한 레퍼런스는 다음을 참고하라. :ref:`Selector reference <topics-"
"selectors-ref>`"

#: ../docs/topics/selectors.rst:48 ../docs/topics/selectors.rst:83
msgid "Using selectors"
msgstr "셀렉터 사용하기"

#: ../docs/topics/selectors.rst:51
msgid "Constructing selectors"
msgstr "셀렉터 생성하기"

#: ../docs/topics/selectors.rst:55
msgid ""
"Scrapy selectors are instances of :class:`~scrapy.selector.Selector` "
"class constructed by passing **text** or "
":class:`~scrapy.http.TextResponse` object. It automatically chooses the "
"best parsing rules (XML vs HTML) based on input type::"
msgstr ""
"스크래피 셀렉터는 **텍스트** 또는 :class:`~scrapy.http.TextResponse` 객체를 전달해서 생성된 "
":class:`~scrapy.selector.Selector` 클래스의 인스턴스이다 셀렉터는 입력 타입에 기반해 자동으로 최고의 "
"파싱 규칙 (XML vs HTML)을 선택한다::"

#: ../docs/topics/selectors.rst:63
msgid "Constructing from text::"
msgstr "텍트스로 생성하기::"

#: ../docs/topics/selectors.rst:69
msgid "Constructing from response::"
msgstr "리스펀스로 생성하기::"

#: ../docs/topics/selectors.rst:75
msgid ""
"For convenience, response objects expose a selector on `.selector` "
"attribute, it's totally OK to use this shortcut when possible::"
msgstr ""
"편의를 위해, 리스펀스 객체는 `.selector` 속성으로 셀렉터를 사용할 수 있다, 가능할 때 이 방법을 이용하는 것은 전혀 "
"문제가 없다::"

#: ../docs/topics/selectors.rst:85
msgid ""
"To explain how to use the selectors we'll use the `Scrapy shell` (which "
"provides interactive testing) and an example page located in the Scrapy "
"documentation server:"
msgstr ""
"셀렉터를 사용하는 방법을 설명하기 위해서 우리는 (인터렉티브한 테스팅을 제공하는) `Scrapy Shell`\\ 과 스크래피 문서 "
"서버에 있는 예제 페이지를 활용할 것이다:"

#: ../docs/topics/selectors.rst:89
msgid "https://doc.scrapy.org/en/latest/_static/selectors-sample1.html"
msgstr "https://doc.scrapy.org/en/latest/_static/selectors-sample1.html"

#: ../docs/topics/selectors.rst:93
msgid "Here's its HTML code:"
msgstr "아래는 페이지의 HTML 코드다:"

#: ../docs/topics/selectors.rst:100
msgid "First, let's open the shell::"
msgstr "우선 셸(shell)을 열자::"

#: ../docs/topics/selectors.rst:104
msgid ""
"Then, after the shell loads, you'll have the response available as "
"``response`` shell variable, and its attached selector in "
"``response.selector`` attribute."
msgstr ""
"셸이 로드되면 사용자는 ``response`` 셸 변수를 써서 사용 가능한 리스펀스와 ``response.selector`` "
"속성으로 붙은 셀렉터를 갖게 된다."

#: ../docs/topics/selectors.rst:107
msgid ""
"Since we're dealing with HTML, the selector will automatically use an "
"HTML parser."
msgstr "HTML을 처리하고 있기 대문에, 셀렉터는 자동적으로 HTML 파서를 사용한다."

#: ../docs/topics/selectors.rst:111
msgid ""
"So, by looking at the :ref:`HTML code <topics-selectors-htmlcode>` of "
"that page, let's construct an XPath for selecting the text inside the "
"title tag::"
msgstr ""
"페이지의 :ref:`HTML 코드 <topics-selectors-htmlcode>`\\ 를 보고 타이틀 태그에 있는 텍스트를 "
"선택하기 위한 XPath 만들어 보자::"

#: ../docs/topics/selectors.rst:117
msgid ""
"Querying responses using XPath and CSS is so common that responses "
"include two convenience shortcuts: ``response.xpath()`` and "
"``response.css()``::"
msgstr ""
"XPath나 CSS를 사용해 리스펀스를 쿼리하는 것은 매우 일반적인 일이라서 리스펀스는 두 숏컷을 포함하고 있다. "
"``response.xpath()``, ``response.css()``::"

#: ../docs/topics/selectors.rst:125
msgid ""
"As you can see, ``.xpath()`` and ``.css()`` methods return a "
":class:`~scrapy.selector.SelectorList` instance, which is a list of new "
"selectors. This API can be used for quickly selecting nested data::"
msgstr ""
"보다시피, ``.xpath()``\\ 와 ``.css()`` 메서드는 "
":class:`~scrapy.selector.SelectorList` 인스턴스를 반환하며, 이는 새로운 셀렉터 리스트다. 이 "
"API는 중첩된 데이터를 빠르게 선택하는 데 사용할 수 있다::"

#: ../docs/topics/selectors.rst:136
msgid ""
"To actually extract the textual data, you must call the selector "
"``.extract()`` method, as follows::"
msgstr "텍스트 데이터를 실제로 추출하려면 반드시 셀렉터의 ``.extract()`` 메서드를 아래처럼 호출해야 한다::"

#: ../docs/topics/selectors.rst:142
msgid ""
"If you want to extract only first matched element, you can call the "
"selector ``.extract_first()``"
msgstr "가장 첫 번째에 메치된 요소를 추출하려면 셀렉터의 ``.extract_first()`` 메서드를 호출해야 한다."

#: ../docs/topics/selectors.rst:147
msgid "It returns ``None`` if no element was found:"
msgstr "찾아진 요소가 없으면 ``None``\\ 을 반환한다:"

#: ../docs/topics/selectors.rst:152
msgid ""
"A default return value can be provided as an argument, to be used instead"
" of ``None``:"
msgstr "기본 리턴 값을 ``None`` 대신에 주어진 인자로 반환시킬 수 있다.:"

#: ../docs/topics/selectors.rst:157
msgid ""
"Notice that CSS selectors can select text or attribute nodes using CSS3 "
"pseudo-elements::"
msgstr "CSS 셀렉터는 CSS3 수에도-요소(pseudo-element)를 사용해서 텍스트와 속성 노드를 선택할 수 있다::"

#: ../docs/topics/selectors.rst:163
msgid "Now we're going to get the base URL and some image links::"
msgstr "이제 베이스 URL과 몇 가지 이미지 링크를 얻어볼 것이다::"

#: ../docs/topics/selectors.rst:202
msgid "Nesting selectors"
msgstr "셀렉터 중첩하기"

#: ../docs/topics/selectors.rst:204
msgid ""
"The selection methods (``.xpath()`` or ``.css()``) return a list of "
"selectors of the same type, so you can call the selection methods for "
"those selectors too. Here's an example::"
msgstr ""
"선택 메서드(``.xpath()`` 또는 ``.css()``)는 같은 타입의 셀렉터 리스트를 반환한다, 따라서 그 셀렉터에도 선택 "
"메서드를 호출할 수 있다. 아래는 그 예시다::"

#: ../docs/topics/selectors.rst:227
msgid "Using selectors with regular expressions"
msgstr "정규 표현식으로 셀렉터 사용하기"

#: ../docs/topics/selectors.rst:229
msgid ""
":class:`~scrapy.selector.Selector` also has a ``.re()`` method for "
"extracting data using regular expressions. However, unlike using "
"``.xpath()`` or ``.css()`` methods, ``.re()`` returns a list of unicode "
"strings. So you can't construct nested ``.re()`` calls."
msgstr ""
":class:`~scrapy.selector.Selector`\\ 는 정규식을 사용한 데이터 추출을 위해 ``.re()`` 메서드를"
" 제공한다. 그러나 ``.xpath()``\\ 나 ``.css()`` 메서드와는 다르게, ``.re()``\\ 는 유니코드 문자열 "
"리스트를 반환한다. 따라서 중첩된 ``.re()`` 호출을 생성할 수 없다."

#: ../docs/topics/selectors.rst:234
msgid ""
"Here's an example used to extract image names from the :ref:`HTML code "
"<topics-selectors-htmlcode>` above::"
msgstr ""
"아래는 위의 :ref:`HTML code <topics-selectors-htmlcode>`\\ 에서 이미지 이름을 추출하는 "
"예제다::"

#: ../docs/topics/selectors.rst:244
msgid ""
"There's an additional helper reciprocating ``.extract_first()`` for "
"``.re()``, named ``.re_first()``. Use it to extract just the first "
"matching string::"
msgstr ""
"``.re()``\\ 를 위해 ``.extract_first()``\\ 를 반복하는 추가적인 헬퍼가 있으며, 이름은 "
"``.re_first()``\\ 다. 첫 번째로 매치되는 문자열을 추출하기 위해 사용할 수 있다::"

#: ../docs/topics/selectors.rst:253
msgid "Working with relative XPaths"
msgstr "상대 XPath로 작업하기"

#: ../docs/topics/selectors.rst:255
msgid ""
"Keep in mind that if you are nesting selectors and use an XPath that "
"starts with ``/``, that XPath will be absolute to the document and not "
"relative to the ``Selector`` you're calling it from."
msgstr ""
"만약 셀렉터를 중첩하면서 ``/``\\ 로 시작하는 XPath를 사용하는 경우, 그 XPath는 문서에 대해 절대적이며 호출되는 "
"``Selector``\\ 에 대해 상대적이지 않다."

#: ../docs/topics/selectors.rst:259
msgid ""
"For example, suppose you want to extract all ``<p>`` elements inside "
"``<div>`` elements. First, you would get all ``<div>`` elements::"
msgstr ""
"예를 들어 ``<div>`` 요소에 있는 모든 ``<p>`` 요소를 추출하고 싶다고 하자. 우선, 모든 ``<div>`` 요소를 "
"얻는다::"

#: ../docs/topics/selectors.rst:264
msgid ""
"At first, you may be tempted to use the following approach, which is "
"wrong, as it actually extracts all ``<p>`` elements from the document, "
"not only those inside ``<div>`` elements::"
msgstr ""
"처음에, 아래와 같은 접근방식을 사용하려고 시도할 수도 있는데, 이는 잘못됐다, 왜냐하면 ``<div>`` 요소에 있는 것 뿐만 "
"아니라 문서에 있는 모든 ``<p>`` 요소를 다 추출하기 때문이다::"

#: ../docs/topics/selectors.rst:271
msgid ""
"This is the proper way to do it (note the dot prefixing the ``.//p`` "
"XPath)::"
msgstr "아래가 적절한 방식이다 (``.//p`` XPath 가장 앞에 있는 점을 명심하기 바란다)::"

#: ../docs/topics/selectors.rst:276
msgid "Another common case would be to extract all direct ``<p>`` children::"
msgstr "다른 일반적인 경우는 모든 ``<p>`` 자식을 추출하는 것이다::"

#: ../docs/topics/selectors.rst:281
msgid ""
"For more details about relative XPaths see the `Location Paths`_ section "
"in the XPath specification."
msgstr "상대적 XPath에 관한 자세한 정보는 XPath 설명서에 있는 `Location Paths`_\\ 를 참고하라."

#: ../docs/topics/selectors.rst:289
msgid "Variables in XPath expressions"
msgstr "XPath 표현식의 변수"

#: ../docs/topics/selectors.rst:291
msgid ""
"XPath allows you to reference variables in your XPath expressions, using "
"the ``$somevariable`` syntax. This is somewhat similar to parameterized "
"queries or prepared statements in the SQL world where you replace some "
"arguments in your queries with placeholders like ``?``, which are then "
"substituted with values passed with the query."
msgstr ""
"XPath는 XPath 표현식에서 ``$somevariable`` 신택스를 사용해 변수를 참조하는 것을 허용한다. 이는 쿼리 내부의"
" 인자를 ``?`` 같은 플레이스홀더로 대체해놓고 나중에 쿼리에 값을 전달하는 SQL 세계의 파라미터로 나타내진 쿼리 또는 준비된 "
"명령문과 꽤 흡사하다."

#: ../docs/topics/selectors.rst:297
msgid ""
"Here's an example to match an element based on its \"id\" attribute "
"value, without hard-coding it (that was shown previously)::"
msgstr "아래는 (이전에 보여줬었던) 하드 코딩 없이 \"id\" 속성 값에 기반한 요소와 일치시키는 예제다::"

#: ../docs/topics/selectors.rst:304
msgid ""
"Here's another example, to find the \"id\" attribute of a ``<div>`` tag "
"containing five ``<a>`` children (here we pass the value ``5`` as an "
"integer)::"
msgstr ""
"아래는 다섯 개의 ``<a>`` 자식을 포함하는 ``<div>``  태그의 \"id\" 속성을 찾는 또 다른 예제다 (여기서는 "
"integer인 ``5``\\ 를 전달했다)::"

#: ../docs/topics/selectors.rst:310
msgid ""
"All variable references must have a binding value when calling "
"``.xpath()`` (otherwise you'll get a ``ValueError: XPath error:`` "
"exception). This is done by passing as many named arguments as necessary."
msgstr ""
"모든 변수 참조는 ``.xpath()``\\ 를 호출할 때 바인드하는 값이 있어야 한다. (그렇지 않으면 ``ValueError: "
"XPath error:`` 예외가 발생한다). 이는 네임드 인자를 필요한 만큼 전달해서 실행한다."

#: ../docs/topics/selectors.rst:314
msgid ""
"`parsel`_, the library powering Scrapy selectors, has more details and "
"examples on `XPath variables`_."
msgstr "스크래피 셀렉터를 강력하게 해주는 `parsel`_ 라이브러리에 관한 자세한 내용과 예제는 `XPath 변수`_\\ 에 나와있다."

#: ../docs/topics/selectors.rst:321
msgid "Using EXSLT extensions"
msgstr "EXSLT 확장 사용하기"

#: ../docs/topics/selectors.rst:323
msgid ""
"Being built atop `lxml`_, Scrapy selectors also support some `EXSLT`_ "
"extensions and come with these pre-registered namespaces to use in XPath "
"expressions:"
msgstr ""
"`lxml`_ 위에 빌드되어서, 스크래피 셀렉터는 `EXSLT`_ 확장도 지원하며 XPath 표현식에서 사용할 수 있는 사전 등록된"
" 네임스페이스가 존재한다:"

#: ../docs/topics/selectors.rst:328
msgid "prefix"
msgstr "prefix"

#: ../docs/topics/selectors.rst:328
msgid "namespace"
msgstr "namespace"

#: ../docs/topics/selectors.rst:328
msgid "usage"
msgstr "usage"

#: ../docs/topics/selectors.rst:330
msgid "re"
msgstr "re"

#: ../docs/topics/selectors.rst:330
msgid "\\http://exslt.org/regular-expressions"
msgstr "\\http://exslt.org/regular-expressions"

#: ../docs/topics/selectors.rst:330
msgid "`regular expressions`_"
msgstr "`regular expressions`_"

#: ../docs/topics/selectors.rst:331
msgid "set"
msgstr "set"

#: ../docs/topics/selectors.rst:331
msgid "\\http://exslt.org/sets"
msgstr "\\http://exslt.org/sets"

#: ../docs/topics/selectors.rst:331
msgid "`set manipulation`_"
msgstr "`set manipulation`_"

#: ../docs/topics/selectors.rst:335
msgid "Regular expressions"
msgstr "정규 표현식"

#: ../docs/topics/selectors.rst:337
msgid ""
"The ``test()`` function, for example, can prove quite useful when XPath's"
" ``starts-with()`` or ``contains()`` are not sufficient."
msgstr ""
"예를 들어 ``test()`` 함수는, XPath의 ``starts-with()`` 또는 ``contains()``\\ 가 충분하지"
" 않을 때 꽤 유용하다."

#: ../docs/topics/selectors.rst:340
msgid ""
"Example selecting links in list item with a \"class\" attribute ending "
"with a digit::"
msgstr "숫자로 끝나는 \"class\" 속성을 가진 리스트 아이템에서 링크를 선택하는 예제::"

#: ../docs/topics/selectors.rst:361
msgid ""
"C library ``libxslt`` doesn't natively support EXSLT regular expressions "
"so `lxml`_'s implementation uses hooks to Python's ``re`` module. Thus, "
"using regexp functions in your XPath expressions may add a small "
"performance penalty."
msgstr ""
"C 라이브러리 ``libxslt``\\ 는 기본적으로 EXSLT 정규 표현식을 지원하지 않는다. 따라서 `lxml`_\\ 의 구현은"
" 파이썬의 ``re`` 모듈을 사용한다. 그러므로 정규식 함수를 XPath 표현식에서 사용하는 것은 성능 측면에서 작은 패널티를 "
"주게 된다."

#: ../docs/topics/selectors.rst:367
msgid "Set operations"
msgstr "세트 작업"

#: ../docs/topics/selectors.rst:369
msgid ""
"These can be handy for excluding parts of a document tree before "
"extracting text elements for example."
msgstr "텍스트 요소를 추출하기 전에 문서트리의 일부를 제외시키는 것이 편리할 수 있다."

#: ../docs/topics/selectors.rst:372
msgid ""
"Example extracting microdata (sample content taken from "
"http://schema.org/Product) with groups of itemscopes and corresponding "
"itemprops::"
msgstr ""
"아이템스코프(itemscope)와 대응하는 아이템프롭(itemprop)이 그룹이 있는 마이크로데이터를 추출하는 예제 (샘플 컨텐츠는"
" http://schema.org/Product\\ 에서 가져왔다::"

#: ../docs/topics/selectors.rst:457
msgid ""
"Here we first iterate over ``itemscope`` elements, and for each one, we "
"look for all ``itemprops`` elements and exclude those that are themselves"
" inside another ``itemscope``."
msgstr ""
"위에서 우리는 일단 ``itemscope`` 요소에 대해 반복을 했고, 각각에 대해 모든 ``itemprops`` 요소를 찾았다. "
"그 다음 또다른 ``itemscope`` 안에 있는 것들을 제외시켰다."

#: ../docs/topics/selectors.rst:467
msgid "Some XPath tips"
msgstr "XPath 팁"

#: ../docs/topics/selectors.rst:469
msgid ""
"Here are some tips that you may find useful when using XPath with Scrapy "
"selectors, based on `this post from ScrapingHub's blog`_. If you are not "
"much familiar with XPath yet, you may want to take a look first at this "
"`XPath tutorial`_."
msgstr ""
"스크래피 셀렉터로 XPath를 사용할 때 유용한 팁들이 `ScrapingHub의 블로그 포스트`_\\ 에 있다. XPath에 아직 "
"익숙하지 않다면 먼저 `XPath 튜토리얼`_\\ 을 보는 것도 좋다."

#: ../docs/topics/selectors.rst:480
msgid "Using text nodes in a condition"
msgstr "조건이 있는 텍스트 노드 사용하기"

#: ../docs/topics/selectors.rst:482
msgid ""
"When you need to use the text content as argument to an `XPath string "
"function`_, avoid using ``.//text()`` and use just ``.`` instead."
msgstr ""
"`XPath string function`_\\ 에 인자로 텍스트 건텐츠를 사용할 필요가 있을 때, ``.//text()``\\ "
"사용을 피하고 ``.``\\ 만 사용하라."

#: ../docs/topics/selectors.rst:485
msgid ""
"This is because the expression ``.//text()`` yields a collection of text "
"elements -- a *node-set*. And when a node-set is converted to a string, "
"which happens when it is passed as argument to a string function like "
"``contains()`` or ``starts-with()``, it results in the text for the first"
" element only."
msgstr ""
"왜냐하면 ``.//text()`` 표현은 텍스트 요소의 집합을 생산하기 때문이다 -- *노드-세트* . 그리고 "
"``contains()`` 또는 ``starts-with()`` 같은 문자열 함수에 인자로 전달돼서 노드-세트가 문자열로 변환될 "
"때, 첫 번째 요소에 대한 텍스트만 불러온다."

#: ../docs/topics/selectors.rst:489 ../docs/topics/selectors.rst:527
msgid "Example::"
msgstr "예::"

#: ../docs/topics/selectors.rst:494
msgid "Converting a *node-set* to string::"
msgstr "*노드-세트*\\ 를 문자열로 변환::"

#: ../docs/topics/selectors.rst:501
msgid ""
"A *node* converted to a string, however, puts together the text of itself"
" plus of all its descendants::"
msgstr "그러나 문자열로 변환된 *노드*\\ 는 텍스트와 모든 디센던트(descendant)를 합쳐버린다::"

#: ../docs/topics/selectors.rst:508
msgid "So, using the ``.//text()`` node-set won't select anything in this case::"
msgstr "따라서, ``.//text()`` 노드-세트를 사용하는 것은 이 경우에 아무것도 선택하지 않는다::"

#: ../docs/topics/selectors.rst:513
msgid "But using the ``.`` to mean the node, works::"
msgstr "하지만 노드를 의미하는 ``.``\\ 를 사용하면 작동한다::"

#: ../docs/topics/selectors.rst:521
msgid "Beware of the difference between //node[1] and (//node)[1]"
msgstr "//node[1]와 (//node)[1]의 차이를 주의하라"

#: ../docs/topics/selectors.rst:523
msgid ""
"``//node[1]`` selects all the nodes occurring first under their "
"respective parents."
msgstr "``//node[1]``\\ 는 각각의 부모 아래서 처음으로 발생하는 모든 노드를 선택한다."

#: ../docs/topics/selectors.rst:525
msgid ""
"``(//node)[1]`` selects all the nodes in the document, and then gets only"
" the first of them."
msgstr "``(//node)[1]``\\ 는 문서 내에서 모든 노드를 선택하고, 그중 첫 번째만 가져온다."

#: ../docs/topics/selectors.rst:543
msgid "This gets all first ``<li>``  elements under whatever it is its parent::"
msgstr "아래는 부모에 상관없이 모든 첫 번째 ``<li>`` 요소를 가져온다::"

#: ../docs/topics/selectors.rst:548
msgid "And this gets the first ``<li>``  element in the whole document::"
msgstr "그리고 아래는 전체 문서의 첫 번째 ``<li>`` 요소만 가져온다::"

#: ../docs/topics/selectors.rst:553
msgid "This gets all first ``<li>``  elements under an ``<ul>``  parent::"
msgstr "아래는 ``<ul>`` 부모 아래 있는 모든 첫 번째 ``<li>`` 요소만 가지고 온다::"

#: ../docs/topics/selectors.rst:558
msgid ""
"And this gets the first ``<li>``  element under an ``<ul>``  parent in "
"the whole document::"
msgstr "그리고 아래는 전체 문서의 ``<ul>`` 부모 아래 있는 첫 번째 ``<li>`` 요소만 가지고 온다::"

#: ../docs/topics/selectors.rst:564
msgid "When querying by class, consider using CSS"
msgstr "클래스로 쿼리 할 때, CSS 사용을 고려하라"

#: ../docs/topics/selectors.rst:566
msgid ""
"Because an element can contain multiple CSS classes, the XPath way to "
"select elements by class is the rather verbose::"
msgstr "요소가 여러 CSS 클래스를 포함할 수 있기 때문에, 클래스로 요소를 선택하는 XPath 방식은 다소 장황하다::"

#: ../docs/topics/selectors.rst:571
msgid ""
"If you use ``@class='someclass'`` you may end up missing elements that "
"have other classes, and if you just use ``contains(@class, 'someclass')``"
" to make up for that you may end up with more elements that you want, if "
"they have a different class name that shares the string ``someclass``."
msgstr ""
"만약 ``@class='someclass'``\\ 로 쓴다면 다른 클래스를 가진 요소를 놓치게 될 것이다. 그리고 "
"``contains(@class, 'someclass')``\\ 로 쓰면 ``someclass`` 문자열을 공유하는 다른 클래스 "
"이름이 있으면 원하는 것 보다 많은 요소를 얻게 된다."

#: ../docs/topics/selectors.rst:576
msgid ""
"As it turns out, Scrapy selectors allow you to chain selectors, so most "
"of the time you can just select by class using CSS and then switch to "
"XPath when needed::"
msgstr ""
"스크래피 셀렉터는 셀렉터를 연결시켜서 사용할 수 있기 때문에, 대부분의 경우 CSS를 사용해 클래스로 선택을 한 다음 필요할 때 "
"XPath로 전환하면 된다::"

#: ../docs/topics/selectors.rst:584
msgid ""
"This is cleaner than using the verbose XPath trick shown above. Just "
"remember to use the ``.`` in the XPath expressions that will follow."
msgstr ""
"이것은 위의 장황한 XPath 트릭을 사용하는 것 보다 훨씬 깔끔하다. 단지 뒤따르는 XPath 표현식에서 ``.``\\ 를 "
"사용하는 것을 기억하라."

#: ../docs/topics/selectors.rst:591
msgid "Built-in Selectors reference"
msgstr "내장 셀렉터 레퍼런스"

#: ../docs/topics/selectors.rst:597
msgid "Selector objects"
msgstr "Selector 객체"

#: ../docs/topics/selectors.rst:601
msgid ""
"An instance of :class:`Selector` is a wrapper over response to select "
"certain parts of its content."
msgstr ""
"``response``\\ 는 데이터 선택이나 추출에 사용될 :class:`~scrapy.http.HtmlResponse` 또는 "
":class:`~scrapy.http.XmlResponse` 객체다."

#: ../docs/topics/selectors.rst:604
msgid ""
"``response`` is an :class:`~scrapy.http.HtmlResponse` or an "
":class:`~scrapy.http.XmlResponse` object that will be used for selecting "
"and extracting data."
msgstr ""
"``text``\\ 는 유니코드 문자열이고 ``response``\\ 가 사용 불가능할 때는 utf-8로 인코딩 텍스트가 된다. "
"``text``\\ 와 ``response`` 같이 사용하는 것은 정의되지 않은 동작이다."

#: ../docs/topics/selectors.rst:608
msgid ""
"``text`` is a unicode string or utf-8 encoded text for cases when a "
"``response`` isn't available. Using ``text`` and ``response`` together is"
" undefined behavior."
msgstr ""
"``type``\\ 는 셀렉터 타입을 정의한다. ``\"html\"``, ``\"xml\"`` 또는 ``None`` (기본)이 될 "
"수 있다."

#: ../docs/topics/selectors.rst:612
msgid ""
"``type`` defines the selector type, it can be ``\"html\"``, ``\"xml\"`` "
"or ``None`` (default)."
msgstr ""
"만약 ``type``\\ 이 ``None``\\ 이면, 셀렉터는 자동으로 최선의 타입(type)을 ``response`` 타입에 "
"기반해 고르며(아래를 참고하라), ``text``\\ 와 같이 쓰이는 경우는 ``\"html\"``\\ 이 기본으로 설정되어 있다."

#: ../docs/topics/selectors.rst:614
msgid ""
"If ``type`` is ``None``, the selector automatically chooses the best type"
" based on ``response`` type (see below), or defaults to ``\"html\"`` in "
"case it is used together with ``text``."
msgstr ""
"``type``\\ 이 ``None``\\ 이고 ``response``\\ 가 전달 되었으면, 셀렉터 타입은 아래처럼 리스펀스 "
"타입에 따라 추정된다:"

#: ../docs/topics/selectors.rst:618
msgid ""
"If ``type`` is ``None`` and a ``response`` is passed, the selector type "
"is inferred from the response type as follows:"
msgstr ":class:`~scrapy.http.HtmlResponse` 타입의 경우 ``\"html\"``"

#: ../docs/topics/selectors.rst:621
msgid "``\"html\"`` for :class:`~scrapy.http.HtmlResponse` type"
msgstr ":class:`~scrapy.http.XmlResponse` 타입의 경우 ``\"xml\"``"

#: ../docs/topics/selectors.rst:622
msgid "``\"xml\"`` for :class:`~scrapy.http.XmlResponse` type"
msgstr "그 이외의 타입의 경우 ``\"html\"``"

#: ../docs/topics/selectors.rst:623
msgid "``\"html\"`` for anything else"
msgstr "이외의 경우에 ``type``\\ 이 설정되어 있으면, 셀렉터 타입이 강제되어 탐색이 일어나지 않을 수 있다."

#: ../docs/topics/selectors.rst:625
msgid ""
"Otherwise, if ``type`` is set, the selector type will be forced and no "
"detection will occur."
msgstr ""

#: ../docs/topics/selectors.rst:630
msgid ""
"Find nodes matching the xpath ``query`` and return the result as a "
":class:`SelectorList` instance with all elements flattened. List elements"
" implement :class:`Selector` interface too."
msgstr ""
"xpath ``query``\\ 와 매치되는 노드를 찾고 일자화된(flattened) 모든 요소를 포함한 "
":class:`SelectorList` 인스턴스를 결과로 반환한다. 리스트 요소 또한 :class:`Selector` 인터페이스를 "
"구현하고 있다."

#: ../docs/topics/selectors.rst:634
msgid "``query`` is a string containing the XPATH query to apply."
msgstr "``query``\\ 는 문자열로 사용할 XPATH 쿼리를 포함하고 있다."

#: ../docs/topics/selectors.rst:638
msgid "For convenience, this method can be called as ``response.xpath()``"
msgstr "편의를 위해, 이 메서드는 ``response.xpath()``\\ 로 호출될 수 있다."

#: ../docs/topics/selectors.rst:642
msgid "Apply the given CSS selector and return a :class:`SelectorList` instance."
msgstr "주어진 CSS 셀렉터를 적용하고 :class:`SelectorList` 인스턴스를 반환한다."

#: ../docs/topics/selectors.rst:644
msgid "``query`` is a string containing the CSS selector to apply."
msgstr "``query``\\ 는 사용할 CSS 셀렉터를 포함하고 있는 문자열이다."

#: ../docs/topics/selectors.rst:646
msgid ""
"In the background, CSS queries are translated into XPath queries using "
"`cssselect`_ library and run ``.xpath()`` method."
msgstr ""
"뒷단에서, CSS 쿼리는 `cssselect`_ 라이브러리를 사용해서 XPath 쿼리로 변경되고 ``.xpath()`` 메서드를 "
"실행한다."

#: ../docs/topics/selectors.rst:651
msgid "For convenience this method can be called as ``response.css()``"
msgstr "편의를 위해 이 메서드는 ``response.css()``\\ 로 호출된다."

#: ../docs/topics/selectors.rst:655
msgid ""
"Serialize and return the matched nodes as a list of unicode strings. "
"Percent encoded content is unquoted."
msgstr "매치된 노드를 유니코드 문자열 리스트로 직렬화(serialize)하고 반환한다. 퍼센트 인코딩된 컨텐츠는 인용부호가 없다."

#: ../docs/topics/selectors.rst:660
msgid ""
"Apply the given regex and return a list of unicode strings with the "
"matches."
msgstr "주어진 정규표현식을 적용하고 칠치하는 유니코드 문자열의 리스트를 반환한다.\\"

#: ../docs/topics/selectors.rst:663
msgid ""
"``regex`` can be either a compiled regular expression or a string which "
"will be compiled to a regular expression using ``re.compile(regex)``"
msgstr ""
"``regex``\\ 는 컴파일된 정규표현식이나 문자열이면 된다. 문자열은 ``re.compile(regex)``\\ 를 사용해 "
"정규 표현식으로 컴파일된다."

#: ../docs/topics/selectors.rst:668
msgid ""
"Note that ``re()`` and ``re_first()`` both decode HTML entities (except "
"``&lt;`` and ``&amp;``)."
msgstr ""
"``re()``\\ 와 ``re_first()``\\ 는 모두 HTML 엔티티(entity)를 디코딩한다. (``&lt;``, "
"``&amp;`` 제외)"

#: ../docs/topics/selectors.rst:672
msgid ""
"Register the given namespace to be used in this :class:`Selector`. "
"Without registering namespaces you can't select or extract data from non-"
"standard namespaces. See examples below."
msgstr ""
":class:`Selector`\\ 에서 사용될 주어진 네임스페이스(name space)를 등록한다. 네임스페이스를 등록하지 않으면"
" 비표준 네임스페이스로부터 데이터를 추출하거나 선택할 수 없다. 아래의 예제를 참고하라."

#: ../docs/topics/selectors.rst:678
msgid ""
"Remove all namespaces, allowing to traverse the document using namespace-"
"less xpaths. See example below."
msgstr "모든 네임스페이스를 제거하고, 네임스페이스 없는 xpath를 사용해서 문서를 돌아다니게 해준다. 아래의 예제를 참고하라."

#: ../docs/topics/selectors.rst:683
msgid ""
"Returns ``True`` if there is any real content selected or ``False`` "
"otherwise.  In other words, the boolean value of a :class:`Selector` is "
"given by the contents it selects."
msgstr ""
"선택된 실제 컨텐츠가 있으면 ``True``\\ 를 반환하고 그렇지 않은 경우에는 ``False``\\ 를 반환한다. 즉, "
":class:`Selector`\\ 의 불리언(Boolean) 값은 셀렉터가 선택하는 컨텐츠에 따라 달라진다."

#: ../docs/topics/selectors.rst:689
msgid "SelectorList objects"
msgstr "SelectorList 객체"

#: ../docs/topics/selectors.rst:693
msgid ""
"The :class:`SelectorList` class is a subclass of the builtin ``list`` "
"class, which provides a few additional methods."
msgstr ":class:`SelectorList` 클래스는 내장 ``list`` 클래스의 상속 클래스로 추가적인 메서드를 제공한다."

#: ../docs/topics/selectors.rst:698
msgid ""
"Call the ``.xpath()`` method for each element in this list and return "
"their results flattened as another :class:`SelectorList`."
msgstr ""
"리스트에 있는 각 요소에 대해 ``.xpath()`` 메서드를 호출하고 일자화된 결과를 또다른 "
":class:`SelectorList`\\ 로 반환한다."

#: ../docs/topics/selectors.rst:701
msgid "``query`` is the same argument as the one in :meth:`Selector.xpath`"
msgstr "``query``\\ 는 :meth:`Selector.xpath`\\ 에 있는 인자와 같다."

#: ../docs/topics/selectors.rst:705
msgid ""
"Call the ``.css()`` method for each element in this list and return their"
" results flattened as another :class:`SelectorList`."
msgstr ""
"리스트에 있는 각 요소에 대해 ``.css()`` 메서드를 호출하고 일자화된 결과를 또다른 "
":class:`SelectorList`\\ 로 반환한다."

#: ../docs/topics/selectors.rst:708
msgid "``query`` is the same argument as the one in :meth:`Selector.css`"
msgstr "``query`` :meth:`Selector.css`\\ 에 있는 인자와 같다."

#: ../docs/topics/selectors.rst:712
msgid ""
"Call the ``.extract()`` method for each element in this list and return "
"their results flattened, as a list of unicode strings."
msgstr "리스트에 있는 각 요소에 대해 ``.extract()`` 메서드를 호출하고 일자화된 유니코드 문자열 리스트를 반환한다."

#: ../docs/topics/selectors.rst:717
msgid ""
"Call the ``.re()`` method for each element in this list and return their "
"results flattened, as a list of unicode strings."
msgstr "리스트에 있는 각 요소에 대해 ``.re()`` 메서드를 호출하고 일자화된 유니코드 문자열 리스트를 반환한다."


#: ../docs/topics/selectors.rst:722
msgid "Selector examples on HTML response"
msgstr "HTML 리스펀스에 관한 셀렉터 예시"

#: ../docs/topics/selectors.rst:724
msgid ""
"Here's a couple of :class:`Selector` examples to illustrate several "
"concepts. In all cases, we assume there is already a :class:`Selector` "
"instantiated with a :class:`~scrapy.http.HtmlResponse` object like this::"
msgstr ""
"이 섹션에는 여러 개념을 설명하기 위한 몇 가지 :class:`Selector` 예시가 있다. 모든 예시에서 "
":class:`~scrapy.http.HtmlResponse`\\ 를 받아 인스턴스화된 :class:`Selector`\\ 가 이미"
" 존재한다고 가정한다::"

#: ../docs/topics/selectors.rst:730
msgid ""
"Select all ``<h1>`` elements from an HTML response body, returning a list"
" of :class:`Selector` objects (ie. a :class:`SelectorList` object)::"
msgstr ""
"HTML 리스펀스 본문(body)로부터 모든 ``<h1>`` 요소를 선택하고, :class:`Selector` 객체 리스트를 "
"반환한다. (:class:`SelectorList` 객체)::"

#: ../docs/topics/selectors.rst:735
msgid ""
"Extract the text of all ``<h1>`` elements from an HTML response body, "
"returning a list of unicode strings::"
msgstr "HTML 리스펀스 폰문으로부터 모든 ``<h1>`` 요소의 텍스트를 추출하고 유니코드 문자열 리스트를 반환한다::"

#: ../docs/topics/selectors.rst:741
msgid "Iterate over all ``<p>`` tags and print their class attribute::"
msgstr "모든``<p>`` 태그에 대해서 반복해서 각각의 클래스 속성을 출력한다::"

#: ../docs/topics/selectors.rst:747
msgid "Selector examples on XML response"
msgstr "XML 리스펀스에 관한 셀렉터 예시"

#: ../docs/topics/selectors.rst:749
msgid ""
"Here's a couple of examples to illustrate several concepts. In both cases"
" we assume there is already a :class:`Selector` instantiated with an "
":class:`~scrapy.http.XmlResponse` object like this::"
msgstr ""
"이 섹션에는 여러가지 개념을 설명하기 위한 몇 가지 예제가 있다. 두 경우 모두In both cases we "
":class:`~scrapy.http.XmlResponse`\\ 로 인스턴스화한 :class:`Selector`\\ 가 이미 "
"존재한다고 가정한다::"

#: ../docs/topics/selectors.rst:755
msgid ""
"Select all ``<product>`` elements from an XML response body, returning a "
"list of :class:`Selector` objects (ie. a :class:`SelectorList` object)::"
msgstr ""
"모든 ``<product>`` 요소를 XML 리스펀스 본문으로부터 선택하고, :class:`Selector` 객체 리스트를 "
"반환한다. (:class:`SelectorList` 객체)::"

#: ../docs/topics/selectors.rst:760
msgid ""
"Extract all prices from a `Google Base XML feed`_ which requires "
"registering a namespace::"
msgstr "네임스페이스 등록을 필요로하는 `Google Base XML feed`_ \\ 에서 모든 가격을 추출한다::"

#: ../docs/topics/selectors.rst:769
msgid "Removing namespaces"
msgstr "네임스페이스 제거"

#: ../docs/topics/selectors.rst:771
msgid ""
"When dealing with scraping projects, it is often quite convenient to get "
"rid of namespaces altogether and just work with element names, to write "
"more simple/convenient XPaths. You can use the "
":meth:`Selector.remove_namespaces` method for that."
msgstr ""
"스크래핑 프로젝트를 다룰 때, 네임스페이스를 완전히 제거하고 요소 이름으로만 작업하는 것이 더 단순하고 편리한 XPath를 "
"작성하기에 꽤 편할 떄가 있다. 이를 위해서 :meth:`Selector.remove_namespaces` 메서드를 사용할 수 "
"있다."

#: ../docs/topics/selectors.rst:776
msgid "Let's show an example that illustrates this with GitHub blog atom feed."
msgstr "GitHub 블로그 아톰 피드(atom feed)로 이를 설명하는 예시를 보자."

#: ../docs/topics/selectors.rst:780
msgid "First, we open the shell with the url we want to scrape::"
msgstr "우선, 스크랩하려는 url로 셀을 열었다::"

#: ../docs/topics/selectors.rst:786
msgid ""
"Once in the shell we can try selecting all ``<link>`` objects and see "
"that it doesn't work (because the Atom XML namespace is obfuscating those"
" nodes)::"
msgstr ""
"셸에서 모든 ``<link>`` 객체를 선택하려고 시도하면 이것이 작동하지 않는 것을 볼 수 있다 (왜냐하면 Atom XML "
"네입스페이스는 노드를 혼란스럽게 만들고 있기 때문이다)::"

#: ../docs/topics/selectors.rst:792
msgid ""
"But once we call the :meth:`Selector.remove_namespaces` method, all nodes"
" can be accessed directly by their names::"
msgstr ""
"하지만 일단 :meth:`Selector.remove_namespaces` 메서드를 호출하면, 모든 노드는 자신의 이름으로 바로 "
"접근할 수가 있다::"

#: ../docs/topics/selectors.rst:801
msgid ""
"If you wonder why the namespace removal procedure isn't always called by "
"default instead of having to call it manually, this is because of two "
"reasons, which, in order of relevance, are:"
msgstr ""
"네임스페이스 제거 과정을 직접 호출하는 대신에 항상 기본으로 호출되지 않게 해놨는지 궁금하다면 이는 두 가지 이유 때문이다. 관련성"
" 순서대로:"

#: ../docs/topics/selectors.rst:805
msgid ""
"Removing namespaces requires to iterate and modify all nodes in the "
"document, which is a reasonably expensive operation to perform for all "
"documents crawled by Scrapy"
msgstr ""
"네임스페이스를 제거하는 것은 문서에 있는 모든 노드를 수정하고 반복하는 것을 요구한다. 이는 스크래피로 크롤링되는 문서에 대해 "
"수행하기에는 상당히 비용이 많이 드는 작업이다."

#: ../docs/topics/selectors.rst:809
msgid ""
"There could be some cases where using namespaces is actually required, in"
" case some element names clash between namespaces. These cases are very "
"rare though."
msgstr ""
"네임스페이스가 실제로 필요한 경우가 있을 수 있다. 그 경우 몇 요소의 이름은 네임스페이스 사이에서 충돌을 일으킨다. 이런 경우는 "
"매우 드물기는 하다."
